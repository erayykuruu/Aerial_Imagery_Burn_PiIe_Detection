# Aerial Imagery Burn Pile Detection
 Using Transfer Learning with DETR , YoloV6 and Yolov8 models


Forest fires damage ecosystems, wildlife, and human life. Burning debris and deadwood is a
common method of management, but unattended piles can reignite and worsen the damage.
Therefore, detecting and monitoring these piles is crucial to prevent harm. Over the last few
years, the use of aerial imagery for detecting and monitoring burn piles has become
increasingly popular. In this thesis, it is proposed a deep learning-based approach for detecting
burn piles in aerial imagery. In this thesis, it was tried to propose a deep learning-based
approach for detecting burn piles in aerial imagery. It got benefited various deep learning
methods which are CNNâ€™s and transfer learning to build an accurate and efficient burn pile
detection model. The proposed approach can detect burn piles with high accuracy and can be
deployed on large-scale aerial imagery datasets. To demonstrate how much effective the
proposed approach, it is conducted experiments on publicly available datasets of aerial
imagery. FLAME did help about providing a dataset of aerial images of fires along with
processes for burn pile detection. With the results, it can be seen that our model outperforms
existing state-of-the-art methods in detecting burn piles accurately and efficiently. Overall,
this thesis presents a novel approach for detecting burn piles in aerial imagery using deep
learning techniques. The proposed approach can significantly reduce the time and effort
required to monitor burn piles and can help prevent further damage caused by forest fires.
There are 3 classes in this data set. These 3 classes are labeled as Fire, No-Fire and Smoke.
This thesis has showed a fire image dataset collected with drones during a burning-piled
detritus in an Arizona pine forest. In this thesis, using YOLOv6, YOLOv8 and DETR deep learning
techniques. Experiment results demonstrate that YOLOv8 reached the highest accuracy with
a mAP score of 94.1, while DETR outperformed other methods with the lowest loss rate of
0.28.
